---
{"dg-publish":true,"permalink":"/03 pages/301机器学习/正则化/","tags":["NLP"],"created":"2024-11-30T20:57:02.555+08:00","updated":"2025-03-14T22:43:35.720+08:00"}
---

## 正则化的使用方法
将正则化应用在[[03 pages/301机器学习/代价函数\|代价函数]]中，使用正则化来减小参数的大小
![](/img/user/09 settings/Z attachment/Snipaste_2023-06-14_09-11-09.png)
如何理解上式？
因为 $w_3^2$ 和 $w_4^2$ 前的系数非常大，要想使整个式子最小化，只能令 $w_3^2$ 和 $w_4^2$ 非常小（$\approx0$），$w_3$ 和 $w_4$ 即为惩罚项。
对于右图过拟合状态，此时 $w_3$ 和 $w_4$ 权重衰减，这样就会降低高阶项对整个函数的影响，使得拟合的函数变得比较平滑。
如果有很多的特征，那如何选择惩罚项呢？
如果有非常多的特征，你可能不知道那些特征重要，以及需要惩罚的特征。通常实现正则化的方式是惩罚**所有**的特征。
对于预测房价实例，比如有 100 个特征，正则化后的代价函数如下：
$$J(\vec{w},b)=\frac{1}{2m}\sum_{i=1}^{m}(f_{\vec{w},b}\big(\vec{x}^{(i)}\big)-y^{(i)}\big)^2+\frac{\lambda}{2m}\sum_{j=1}^{n}\omega_{j}^2$$
把上式分为两部分，左边部分即为原始的代价函数，右边部分为正则化项。λ为超参数，通常会取一个较大的数。
为了最小化整个代价函数，当λ是固定的，那么就要减小 $w_1$ 到 $w_n$ 的值。加入正则项后，$w_1$ 到 $w_n$ 均会减小，也就是使得权重衰减，这样就会降低高阶项对于整个函数的影响，使得估计函数变得比较平滑。
我们还将λ除以 2 m, 这样这里的第一项和第二项都在 2 m 上按比例缩放，会更改容易选择λ的值。按照惯例我们不会因为参数 b 太大而惩罚它，在实践中，做与不做几乎没有什么区别。
因此，总结一下这个修改后的代价函数：
![](/img/user/09 settings/Z attachment/Snipaste_2023-06-14_09-37-48.png)
我们想要最小化\[原始代价函数即均方误差项+第二项即正则化项\]
λ : 可以控制两个不同目标之间的取舍。
此函数有两个目的，目的一：最小化预测值与真实值之间的误差，更好的拟合训练集。目的二：试图减小 $w_j$ ，使假设函数变得“简单”，防止过度拟合。
**两者相互平衡，从而达到一种相互制约的关系，最终找到一个平衡点，从而更好地拟合训练集并且具有良好的泛化能力。**
不同的λ值有什么影响？
使用线性回归的房价预测示例。
如果，λ等于 0，那么正则项等于零，即根本没有使用正则化，会过度拟合。
![](/img/user/09 settings/Z attachment/Snipaste_2023-06-14_09-59-48.png)
当λ非常非常大时，例如 $\lambda=10^{10}$,那么 $w_1到 w_4$ 几乎等于 0，只剩常数 b 项，此时会欠拟合。
![](/img/user/09 settings/Z attachment/Snipaste_2023-06-14_10-00-42.png)
[[03 pages/301机器学习/线性回归\|线性回归]]的正则化方法：
![](/img/user/09 settings/Z attachment/Snipaste_2023-06-14_10-13-49.png)
$$\begin{aligned}
& w_{j}=w_{j}-\alpha\left[\frac{1}{m}\sum_{i=1}^{m}\left[(f_{\vec{{{w}}},b}\big(\vec{x}^{(i)}\big)-y^{(i)}\big)x_{j}^{(i)}\right]+\frac{\lambda}{m}w_{j}\right]  \\
&b=b-\alpha\frac{1}{m}\sum_{i=1}^m(f_{\vec{\mathbf{w}},b}(\vec{\mathbf{x}}^{(i)})-y^{(i)})
\end{aligned}$$
[[03 pages/301机器学习/逻辑回归\|逻辑回归]]的正则化方法：
![](/img/user/09 settings/Z attachment/Snipaste_2023-06-14_10-18-04.png)

## 正则化如何影响方差和偏差
![](/img/user/09 settings/Z attachment/Pasted image 20230713203458.png)

## 正则化中 $\lambda$ 评估
$\lambda$ 与代价函数值图：
![](/img/user/09 settings/Z attachment/Pasted image 20230713204607.png)
$\lambda$ 小，过拟合，$J_{train}$ 低，$J_{cv}$ 高。
$\lambda$ 大，欠拟合，$J_{train}$ 高，$J_{cv}$ 高。
